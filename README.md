# ğŸ§  ImplÃ©mentation d'un ModÃ¨le de Scoring CrÃ©dit

Projet de data science visant Ã  prÃ©dire la probabilitÃ© de dÃ©faut de paiement dâ€™un client Ã  partir de ses donnÃ©es personnelles, financiÃ¨res et historiques de crÃ©dit.  
DonnÃ©es issues de la compÃ©tition Kaggle : [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk/overview).

## ğŸ“ Structure du projet

```
oc-ds-implementer-modele-scoring/
â”œâ”€â”€ data/                      # DonnÃ©es brutes et traitÃ©es (non incluses dans ce repo)
â”œâ”€â”€ notebooks/                # Analyse exploratoire, modÃ©lisation et pipeline
â”‚   â”œâ”€â”€ EDA.ipynb             # Analyse exploratoire des donnÃ©es
â”‚   â”œâ”€â”€ ML.ipynb              # EntraÃ®nement et Ã©valuation des modÃ¨les
â”‚   â””â”€â”€ Pipeline.ipynb        # CrÃ©ation du pipeline final de production
â”œâ”€â”€ models/                   # ModÃ¨les enregistrÃ©s (format .joblib)
â”‚   â”œâ”€â”€ LGBMClassifier_model.joblib        # ModÃ¨le final utilisÃ©
â”‚   â”œâ”€â”€ LogisticRegression_model.joblib
â”‚   â””â”€â”€ RandomForestClassifier_model.joblib
â”œâ”€â”€ monitoring/               # Monitoring des performances et du drift
â”‚   â”œâ”€â”€ data_drift.ipynb
â”‚   â”œâ”€â”€ data_drift_predictions.ipynb
â”‚   â”œâ”€â”€ data_drift_report.html
â”‚   â””â”€â”€ classification_report.html
â”œâ”€â”€ scripts/                  # Scripts principaux
â”‚   â”œâ”€â”€ app.py                # API Flask pour servir le modÃ¨le
â”‚   â”œâ”€â”€ streamlit_app.py      # Interface Streamlit pour tester le scoring par identifiant client
â”‚   â””â”€â”€ versions_lib.py       # Gestion des versions des librairies
â”œâ”€â”€ tests/                    # Tests unitaires
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”œâ”€â”€ Procfile                  # Pour dÃ©ploiement (Heroku par ex.)
â””â”€â”€ .python-version           # Version de Python utilisÃ©e
```

## ğŸš€ FonctionnalitÃ©s

- ğŸ” **Exploration des donnÃ©es**
- ğŸ—ï¸ **CrÃ©ation dâ€™un pipeline de features et modÃ¨le final (LGBMClassifier)**
- ğŸ“Š **Ã‰valuation avec une fonction de coÃ»t personnalisÃ©e**
- ğŸ§ª **Tests API**
- ğŸŒ **API Flask** pour exposer le modÃ¨le [ğŸ‘‰ AccÃ¨s ici](https://ocr-model-scoring-d21bdbd88983.herokuapp.com/)
- ğŸ–¥ï¸ **Interface Streamlit** permettant dâ€™entrer un identifiant client et afficher sa probabilitÃ© de dÃ©faut
- ğŸ“‰ **Monitoring de drift** et suivi des performances du modÃ¨le

---

## âš™ï¸ Installation & Lancement local

### 1. Cloner le repo

```bash
git clone https://github.com/d-walid/oc-ds-implementer-modele-scoring.git
cd oc-ds-implementer-modele-scoring
```

### 2. CrÃ©er un environnement virtuel et installer les dÃ©pendances

```bash
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate sur Windows
pip install -r requirements.txt
```

Le fichier `requirements.txt` contient toutes les librairies nÃ©cessaires (Flask, Streamlit, pandas, joblib, etc.), gÃ©nÃ©rÃ© automatiquement depuis lâ€™environnement utilisÃ© pour entraÃ®ner et dÃ©ployer le modÃ¨le.

---

## ğŸš€ Lancer les applications

### ğŸŒ API Flask

Lâ€™API permet dâ€™interroger le modÃ¨le avec un identifiant client. Pour la lancer :

```bash
python scripts/app.py
```

Accessible localement via [http://127.0.0.1:5000](http://127.0.0.1:5000)

---

### ğŸ–¥ï¸ Interface Streamlit

Lâ€™interface utilisateur Streamlit permet de tester le scoring de clients en saisissant un ID :

```bash
streamlit run scripts/streamlit_app.py
```

Accessible gÃ©nÃ©ralement via [http://localhost:8501](http://localhost:8501)
